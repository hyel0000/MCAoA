# MCAoAN: An Improved Attention Mechanism for Visual Question Answering


This repository is an implementation of the paper "An Improved Attention for Visual Question Answering", which introduces new attention modulesâ€”SAoA (Self Attention on Attention) and GAoA (Guided Attention on Attention)â€”and a novel multi-modal attention fusion method. The project builds upon Yuhao Cui's implementation of MCAN (Modular Co-Attention Network).




## ðŸš€ Project Overview
This project is based on the original MCAN architecture and integrates the following improvements to enhance performance on the Visual Question Answering (VQA) task:

- Modified attention modules: SAoA and GAoA
- Implementation of the multi-modal attention fusion strategy proposed in the paper



## ðŸ“¦ Installation & Usage
The code structure of this project largely follows the original MCAN repository, and the setup and execution process remains the same.

For detailed instructions, please refer to the original implementation:
https://github.com/cuiyuhao1996/mcan-vqa



## ðŸ“œ Citation

If you use this implementation in your work, please cite the following sources:

@article{cui2019mcan,
 title={Deep Modular Co-Attention Networks for Visual Question Answering},
 author={Cui, Yuhao et al.},
 journal={CVPR},
 year={2019},
 note={Original code base used as reference} } 
 
@misc{hyelee2025mcaoan, title={Implementation of MCAoAN: Object-aware Attention Extension of Modular Co-Attention Networks}, author={Hye Lee Kim}, year={2025}, note={Implementation based on the paper "An Improved Attention for Visual Question Answering"} }
